#!/usr/bin/env python
# coding: utf-8

# In[1]:


import random
import math
import re
import csv
import os
import pandas as pd
import sklearn
from sklearn import metrics
from sklearn.utils import shuffle
import numpy as np 
import matplotlib.pyplot as plt #just plot
import seaborn as sns
import keras
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from keras.models import load_model
from keras.models import Model
from keras.layers import LSTM, Dense, Activation, Input, Embedding, Dropout
from keras.optimizers import RMSprop
from keras.preprocessing.text import Tokenizer
from keras.preprocessing import sequence
from keras.utils import to_categorical, pad_sequences
from keras.callbacks import EarlyStopping


# In[2]:


mfiles=[]
bfiles=[]


# In[3]:


for file in os.listdir('C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset'):
    if file.startswith("drebin"):
        mfiles.append(file)
x=len(mfiles)


# In[4]:


for file in os.listdir('C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset'):
    if file.startswith("benign"):
        bfiles.append(file)
y=len(bfiles)


# In[5]:


for i in mfiles:
    fname=str(i)
    data=[]
    path1='C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset\\'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='C:\\Users\\ridas\\MProjSmall(new)\\Malware\\'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)


# In[6]:


for i in bfiles:
    fname=str(i)
    data=[]
    path1='C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset\\'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='C:\\Users\\ridas\\MProjSmall(new)\\Benign\\'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)


# In[10]:


total=x+y
training_m_l=math.ceil(0.7*x)
testing_m_l=x-training_m_l
training_b_l=math.ceil(0.7*y)
testing_b_l=y-training_b_l
training_l=training_m_l+training_b_l
testing_l=testing_m_l+testing_b_l


# In[12]:


print("Total Files:", total)
print("Malware Files:",x)
print("Benign Files:",y)
print("----------------------------------------------")
print("Training Files:", training_l)
print("Training Malware Files:", training_m_l)
print("Training Benign Files:", training_b_l)
print("----------------------------------------------")
print("Testing Files:", testing_l)
print("Testing Malware Files:", testing_m_l)
print("Testing Benign Files:", testing_b_l)
print("----------------------------------------------")


# In[13]:


training_files=[]
testing_files=[]


# In[14]:


random.shuffle(mfiles)
random.shuffle(bfiles)


# In[15]:


for i in range(len(mfiles)):
    if(i<training_m_l):
        training_files.append(mfiles[i])
    elif(i>=training_m_l):
        testing_files.append(mfiles[i])


# In[17]:


for i in range(len(bfiles)):
    if(i<training_b_l):
        training_files.append(bfiles[i])
    elif(i>=training_b_l):
        testing_files.append(bfiles[i])


# In[20]:


for i in training_files:
    fname=str(i)
    data=[]
    path1='C:\\Users\\ridas\\MProjSmall(new)\\Malware\\'+fname
    path2='C:\\Users\\ridas\\MProjSmall(new)\\Benign\\'+fname
    if 'drebin' in fname:
        path=path1
    elif 'benign' in fname:
        path=path2
    with open(path, 'r') as fr:
        data=fr.read()
    path3='C:\\Users\\ridas\\MProjSmall(new)\\Training\\'+fname      
    with open(path3, 'w') as fr:
        fr.write(data)


# In[21]:


for i in testing_files:
    fname=str(i)
    data={}
    path1='C:\\Users\\ridas\\MProjSmall(new)\\Malware\\'+fname
    path2='C:\\Users\\ridas\\MProjSmall(new)\\Benign\\'+fname
    if 'drebin' in fname:
        path=path1
    elif 'benign' in fname:
        path=path2
    with open(path, 'r') as fr:
        data=fr.read()
    path3='C:\\Users\\ridas\\MProjSmall(new)\\Testing\\'+fname      
    with open(path3, 'w') as fr:
        fr.write(data)


# In[22]:


maxlen=0
files=mfiles+bfiles
random.shuffle(files)
for i in files:
    fname=str(i)
    path1='C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset\\'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
        temp=len(data.split())
        maxlen=max(maxlen, temp)
        if(temp<500):
            path2='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+"pt1"+fname
            with open(path2, 'w') as fr:
                fr.write(data)
temp=math.ceil(maxlen/500)


# In[24]:


overlap=[]
for i in files:
    index=1
    words=0
    store=[]
    overlap=[]
    fname=str(i)
    path1='C:\\Users\\ridas\\MProjSmall(new)\\ProcessedDataset\\'+fname
    with open(path1, 'r') as fr:
        lines=fr.readlines()
        y=len(lines)
        for line in lines:
            temp=len(line.split())
            words+=temp
            if(words>=200):
                path2='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+"pt"+str(index)+fname
                with open(path2, 'w') as fr:
                    final=len(store)-3
                    for x in range(len(store)):
                        code=str(store[x])
                        if x>=final:
                            overlap.append(code)
                        fr.write(code)
                words=0
                store=[]
                for j in overlap:
                    words+=len(j.split())
                    store.append(j)
                overlap=[]
                index=index+1
            elif(words<200):
                if(line==lines[y-1]):
                    store.append(line)
                    path2='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+"pt"+str(index)+fname
                    with open(path2, 'w') as fr:
                        for x in store:
                            fr.write(x)
                else:  
                    store.append(line)


# In[27]:


split_files=[]
for file in os.listdir('C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles'):
    if file.endswith(".txt"):
        split_files.append(file)


# In[28]:


for i in split_files:
    fname=str(i)
    path1='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+fname
    done=[]
    with open(path1, 'r') as fr:
        data=fr.read()
        temp=data.split()
        for i in temp:
            done.append(i)
    with open(path1, 'w') as fr:
        for i in done:
            fr.write(i)
            fr.write(" ")


# In[29]:


training_split=[]
testing_split=[]


# In[30]:


for i in split_files:
    name=re.sub('pt[0-9]+', '', i)
    if name in training_files:
        training_split.append(i)
    elif name in testing_files:
        testing_split.append(i)


# In[31]:


print("Total Split Files:", len(split_files))
print("Total Training Files Split:", len(training_split))
print("Total Testing Files Split:", len(testing_split))
print("----------------------------------------------")

# In[32]:


for i in training_split:
    fname=str(i)
    data=[]
    path1='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='C:\\Users\\ridas\\MProjSmall(new)\\TrainingSplit\\'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)


# In[33]:


for i in testing_split:
    fname=str(i)
    data=[]
    path1='C:\\Users\\ridas\\MProjSmall(new)\\AllSplitFiles\\'+fname
    with open(path1, 'r') as fr:
        data=fr.read()
    path2='C:\\Users\\ridas\\MProjSmall(new)\\TestingSplit\\'+fname      
    with open(path2, 'w') as fr:
        fr.write(data)


# In[34]:


final_files=[]
uniq=set()
for i in split_files:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)


# In[35]:


for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, split_files))
    final_files.append(a)
random.shuffle(final_files)


# In[36]:


trainingfiles=[]
testingfiles=[]


# In[37]:


for file in os.listdir('C:\\Users\\ridas\\MProjSmall(new)\\TrainingSplit'):
    if file.endswith(".txt"):
        trainingfiles.append(file)


# In[38]:


for file in os.listdir('C:\\Users\\ridas\\MProjSmall(new)\\TestingSplit'):
    if file.endswith(".txt"):
        testingfiles.append(file)


# In[39]:


finaltrain=[]
finaltest=[]


# In[40]:


uniq=set()
for i in trainingfiles:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)


# In[41]:


for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, trainingfiles))
    finaltrain.append(a)
random.shuffle(finaltrain)


# In[42]:


uniq=set()
for i in testingfiles:
    name=re.sub('pt[0-9]+', '', i)
    uniq.add(name)


# In[43]:


for i in uniq:
    s=".*"+i
    r=re.compile(s)
    a=list(filter(r.match, testingfiles))
    finaltest.append(a)
random.shuffle(finaltest)


# In[44]:


testparts={}
for i in finaltest:
    temp=i
    for x in temp:
        name=re.sub('pt[0-9]+', '', x)
        testparts[name]=len(temp)


# In[45]:


parts=[]
uniqfilenames=[]
for k, v in testparts.items():
    parts.append(v)
    uniqfilenames.append(k)


# In[46]:


trfiles={}
for i in finaltrain:
    for x in range(len(i)):
        fname=str(i[x])
        path1='C:\\Users\\ridas\\MProjSmall(New)\\TrainingSplit\\'+fname
        with open(path1) as f:
            trfiles[fname]=f.read()


# In[47]:


tesfiles={}
for i in finaltest:
    for x in range(len(i)):
        fname=str(i[x])
        path1='C:\\Users\\ridas\\MProjSmall(New)\\TestingSplit\\'+fname
        with open(path1) as f:
            tesfiles[fname]=f.read()


# In[48]:


dftrain=pd.DataFrame(columns=['Fname','Category', 'Code', 'Length'])
for k, v in trfiles.items():
    classes="ok"
    if "drebin" in k:
        classes="Malware"
    else:
        classes="Benign"
    dftrain=dftrain.append({'Fname':k, 'Category': classes, 'Code': v, 'Length':len(v.split())}, ignore_index=True)


# In[49]:


dftest=pd.DataFrame(columns=['Fname','Category', 'Code', 'Length'])
for k, v in tesfiles.items():
    classes="ok"
    if "drebin" in k:
        classes="Malware"
    else:
        classes="Benign"
    dftest=dftest.append({'Fname':k, 'Category': classes, 'Code': v, 'Length':len(v.split())}, ignore_index=True)


# In[50]:


dfactual=pd.DataFrame(columns=['Fname','ActualCategory'])
for i in uniqfilenames:
    classes="ok"
    if "drebin" in i:
        classes="Malware"
    else:
        classes="Benign"
    dfactual=dfactual.append({'Fname':i, 'ActualCategory':classes }, ignore_index=True)


# In[54]:


tempres=[dftrain, dftest]
result=pd.concat(tempres)
result


# In[55]:


X=result.Code
tk=Tokenizer() 
tk.fit_on_texts(X)
words=tk.texts_to_sequences(X)
vocab=len(tk.word_index)
print("Maximum number of Unique Words:", vocab)
print("----------------------------------------------")


# In[56]:


max_len=-1
for i in range(len(words)):
    if(len(words[i])>max_len):
        max_len=len(words[i])
print("Maximum Length of One File:", max_len)
print("----------------------------------------------")


# In[57]:


trwords=[]
tswords=[]
for i in range(len(words)):
    if i<len(trainingfiles):
        temp=words[i]
        trwords.append(temp)
    else:
        temp=words[i]
        tswords.append(temp)


# In[58]:


trainx=keras.utils.pad_sequences(trwords, maxlen=max_len)
testx=keras.utils.pad_sequences(tswords, maxlen=max_len)


# In[59]:


trainy=dftrain.Category
testy=dftest.Category
le=LabelEncoder()
trainy=le.fit_transform(trainy) 
testy=le.fit_transform(testy) 


# In[61]:


early_stopping = EarlyStopping(monitor='val_accuracy', patience=6)


# In[62]:


inputs=Input(shape=[max_len]) 
layer=Embedding(vocab+1,64,input_length=max_len)(inputs)#Embedding Layer
layer=LSTM(1024, return_sequences=True)(layer)
layer=LSTM(512)(layer)
layer=Dropout(0.2)(layer)
layer=Dense(1)(layer)
layer=Activation('sigmoid')(layer)
model=Model(inputs=inputs, outputs=layer)


# In[63]:


model.compile(loss='binary_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])


# In[64]:

print('\n')
print("----------------------------------------------")
print("Training Begins:")
print("----------------------------------------------")
history=model.fit(trainx, trainy, batch_size=16, epochs=7, validation_split=0.2, callbacks=[early_stopping])


# In[65]:

print('\n')
print("----------------------------------------------")
print("Predicting on Test Data:")
print("----------------------------------------------")
predictions=model.predict(testx)


# In[67]:


predtemp=[]
for i in predictions:
    predtemp.append(i[0])


# In[77]:


finalpred=[]
index=0
for i in parts:
    temp=[]
    for y in range(i):
        temp.append(predtemp[index])
        index=index+1
    finalpred.append(temp)


# In[78]:


testingl=[]
for i in finalpred:
    testingl.append(len(i))


# In[81]:

print('\n')
print('\n')
print("----------------------------------------------")
if(parts==testingl):
    print("Keep Moving, no Errors")
else:
    print("ERROR")
print("----------------------------------------------")

# In[83]:


classes=[]
for i in finalpred:
    flag=True
    for x in i:
        if(x>=0.5):
            flag=False
            break
        else:
            continue
    if(flag):
        classes.append("Benign")
    else:
        classes.append("Malware")


# In[84]:


finalf={}
index=0
for k, v in testparts.items():
    finalf[k]=classes[index]
    index=index+1


# In[85]:


dfpreds=pd.DataFrame(columns=['Fname','PredictedCategory'])
for k, v in finalf.items():
    dfpreds=dfpreds.append({'Fname':k, 'PredictedCategory': v}, ignore_index=True)


# In[114]:


dfpreds


# In[87]:


dfactual


# In[88]:

print('\n')
print('\n')
print("----------------------------------------------")
print("Evaluating Model:")
print("----------------------------------------------")
score=model.evaluate(testx, testy)


# In[107]:


cm=metrics.confusion_matrix(dfactual.ActualCategory, dfpreds.PredictedCategory)


# In[124]:


cmap = sns.color_palette("pastel", as_cmap=True)
ax = sns.heatmap((cm/np.sum(cm, axis=1, keepdims=True))*100, annot=True, cmap=cmap, fmt='.2f')
ax.xaxis.tick_top()
ax.set_title('Confusion Matrix\n');
ax.set_xlabel('\nPredicted values')
ax.set_ylabel('Actual Values ');
ax.xaxis.set_ticklabels(['Benign','Malware'])
ax.yaxis.set_ticklabels(['Benign','Malware'])
plt.show()


# In[125]:


import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Calculate metrics
accuracy = accuracy_score(dfactual.ActualCategory, dfpreds.PredictedCategory)
precision =precision_score(dfactual.ActualCategory, dfpreds.PredictedCategory,pos_label='Benign')
recall = recall_score(dfactual.ActualCategory, dfpreds.PredictedCategory,pos_label='Benign')
f1 = f1_score(dfactual.ActualCategory, dfpreds.PredictedCategory, pos_label='Benign')

# Create a table
data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score'], 
        'Value': [accuracy, precision, recall, f1]}
df = pd.DataFrame(data)
print('\n')
print('\n')
print("----------------------------------------------")
print("Evaluated Parameters: ")
print("----------------------------------------------")
print(df)


# In[ ]:




